% !TEX root = ../main.tex
%

\part{最適化}

\chapter{導入}

この部では，最適化のアルゴリズムをまとめる．

最適化問題は一般に次のように書ける．

\begin{align}\label{eq:optimization_general_problem}
    \text{minimize} \hspace{1em} & f(\bm{x})                 \\
    \text{s.t.} \hspace{1em}     & \bm{g}(\bm{x}) \le \bm{0} \\
                                 & \bm{h}(\bm{x}) = \bm{0}
\end{align}

ここで，
$\bm{x} \in \setR^n$,
$f : \setR^n \to \setR$,
$\bm{g} : \setR^n \to \setR^m$,
$\bm{h} : \setR^n \to \setR^r$
とする．
また，ベクトル同士の「$\le$」による比較は
全ての要素において「$\le$」の関係が成り立つことを意味する．

問題\eqref{eq:optimization_general_problem}において，
関数$f$は目的関数，
$\bm{g}(\bm{x}) \le \bm{0}$, $\bm{h}(\bm{x}) = \bm{0}$は制約条件と呼ばれ，
制約条件を満たす中で目的関数を最小化する問題を示している．
最小化した結果の変数 $\bm{x}$ は最適解と呼ばれ，
目的関数の値は最適値と呼ばれる．

なお，最小化でなく最大化で定式化する場合もあるが，
ここでは最小化に統一して説明する．

最適化のアルゴリズムは，
対称とする問題に制約条件があるものとないものに分けられる．

\chapter{基本的な定義と性質}

\begin{definition}[{\cite[Section 6.4]{Luenberger2003}},{\cite[Section 3.1.1]{Boyd2004}}]
    関数 $f : \setR^n \to \setR$ が
    $\forall \bm{x}, \bm{y} \in \setR^n$, $\forall \alpha \in [0, 1]$ に対して
    \begin{equation}
        f\left(\alpha \bm{x} + (1-\alpha) \bm{y}\right)
        \le \alpha f(\bm{x}) + (1-\alpha) f(\bm{y})
    \end{equation}
    を満たす場合，関数 $f$ を凸関数（convex function）と呼ぶ．
\end{definition}

\begin{theorem}[{\cite[Section 6.4]{Luenberger2003}},{\cite[Section 3.1.3]{Boyd2004}}]
    $C^1$ 級関数 $f : \setR^n \to \setR$ が凸関数であるための必要十分条件は
    $\forall \bm{x}, \bm{y} \in \setR^n$ に対して
    \begin{equation}
        f(\bm{y}) \ge f(\bm{x}) + \nabla f(\bm{x})^\top (\bm{y} - \bm{x})
    \end{equation}
    が成り立つことである．
\end{theorem}

\begin{theorem}[{\cite[Section 6.4]{Luenberger2003}},{\cite[Section 3.1.3]{Boyd2004}}]
    $C^2$ 級関数 $f : \setR^n \to \setR$ が凸関数であるための必要十分条件は
    $\forall \bm{x} \in \setR^n$ に対して
    \begin{equation}
        \nabla^2 f(\bm{x}) \succeq O
    \end{equation}
    が成り立つことである．
\end{theorem}

\begin{definition}[{\cite[Section 6.4]{Luenberger2003}},{\cite[Section 3.1.1]{Boyd2004}}]
    関数 $f : \setR^n \to \setR$ が
    $\forall \bm{x}, \bm{y} \in \setR^n$, $\forall \alpha \in [0, 1]$ に対して
    \begin{equation}
        f\left(\alpha \bm{x} + (1-\alpha) \bm{y}\right)
        < \alpha f(\bm{x}) + (1-\alpha) f(\bm{y})
    \end{equation}
    を満たす場合，関数 $f$ は狭義凸関数（strictly convex function）であるという．
\end{definition}

\begin{definition}[{\cite[Section 9.1.2]{Boyd2004}}]
    $C^2$ 級関数 $f : \setR^n \to \setR$ が
    ある定数 $m > 0$ を持ち，
    $\forall \bm{x} \in \setR^n$ に対して
    \begin{equation}
        \nabla^2 f(\bm{x}) \succeq m I
    \end{equation}
    を満たす場合，関数 $f$ は強凸関数（strongly convex function）であるという．
\end{definition}

\begin{theorem}[{\cite[Section 9.1.2]{Boyd2004}}]
    $C^2$ 級関数 $f : \setR^n \to \setR$ が強凸関数である場合，
    $\forall \bm{x}, \bm{y} \in \setR^n$ に対して
    \begin{equation}
        f(\bm{y}) \ge f(\bm{x}) + \nabla f(\bm{x})^\top (\bm{y} - \bm{x})
        + \frac{m}{2} \| \bm{y} - \bm{x} \|_2^2
    \end{equation}
    が成り立つ．
\end{theorem}

\begin{theorem}[{\cite[Section 9.1.2]{Boyd2004}}]
    $C^2$ 級関数 $f : \setR^n \to \setR$ が強凸関数である場合，
    関数 $f$ が最小となる $\bm{x} \in \setR^n$ は一意的に定まる．
\end{theorem}

\input{optimization/one-dim-section-search.tex}
\input{optimization/descent-unconstrained-optimization.tex}
\input{optimization/downhill-simplex.tex}
\input{optimization/global-optimization.tex}
