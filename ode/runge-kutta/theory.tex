% !TEX root = ../../main.tex
%

\index{Runge-Kuttaほう@Runge-Kutta 法}
Runge-Kutta 法 (Runge-Kutta method) では次のような形式の初期値問題を数値的に解く
\cite{Mitsui1993}．
\begin{equation}
    \begin{cases}
        \dot{\bm{y}} = \bm{f}(t, \bm{y}) \\
        \bm{y}(0) = \bm{y}_0
    \end{cases}
\end{equation}

Runge-Kutta 法は，時刻 $t$ における変数 $\bm{y}(t)$ の値から，
次のような形式で時刻 $t + h$ における変数 $\bm{y}(t + h)$ の計算を行う．
\begin{align}
    \bm{k}_i      & = \bm{f}\left(t + b_i h, \bm{y}(t) + h \sum_{j = 1}^s a_{ij} \bm{k}_j \right)
                  & \text{for $i = 1, 2, \ldots, s$}
    \label{eq:ode_runge-kutta_k-law}                                                              \\
    \bm{y}(t + h) & = \bm{y}(t) + h \sum_{i=1}^s c_i \bm{k}_i
    \label{eq:ode_runge-kutta_y-law}
\end{align}

\index{すてっぷはば@ステップ幅}
ここで，時間の更新幅 $h$ はステップ幅と呼ばれる．
Runge-Kutta 法には，
\index{だんすう@段数}
整数 $s$ （段数と呼ばれる）と係数 $a_{ij}$, $b_i$, $c_i$ の異なる様々な公式が存在する．
段数が増えるにつれて数を増していく係数 $a_{ij}$, $b_i$, $c_i$ は
表 \ref{table:ode_runge-kutta_butcher-array-general} のような
\index{Butcherはいれつ@Butcher 配列}
Butcher 配列と呼ばれる形式で記載されることが多い．

\begin{table}[bp]
    \caption{Butcher 配列における係数の並べ方}
    \label{table:ode_runge-kutta_butcher-array-general}
    \centering
    \begin{tabular}{c|ccccc}
        $b_1$    & $a_{11}$ & $a_{12}$ & $a_{13}$ & $\cdots$ & $a_{1s}$ \\
        $b_2$    & $a_{21}$ & $a_{22}$ & $a_{23}$ & $\cdots$ & $a_{2s}$ \\
        $b_3$    & $a_{31}$ & $a_{32}$ & $a_{33}$ & $\cdots$ & $a_{3s}$ \\
        $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\ddots$ & $\vdots$ \\
        $b_s$    & $a_{s1}$ & $a_{s2}$ & $a_{s3}$ & $\cdots$ & $a_{ss}$ \\
        \hline
                 & $c_1$    & $c_2$    & $c_3$    & $\cdots$ & $c_s$
    \end{tabular}
\end{table}

Runge-Kutta 法の公式は次のように分類される \cite{Mitsui1993}．

\begin{description}
    \item[陽的 Runge-Kutta 法 (Explicit Runge-Kutta method, ERK method)]
        $j \ge i$ について $a_{ij} = 0$ となっている場合，
        $\bm{k}i$ は $\bm{k}_1, \bm{k}_2, \ldots, \bm{k}_s$
        の順に式 \eqref{eq:ode_runge-kutta_k-law} の右辺を評価することで計算できる．
        このような場合は
        \index{ようてきRunge-Kuttaほう@陽的 Runge-Kutta 法}
        陽的 Runge-Kutta 法と呼ばれる．
    \item[半陰的 Runge-Kutta 法 (Semi-implicit Runge-Kutta method)]
        $j > i$ について $a_{ij} = 0$ となっている場合，
        $\bm{k}i$ は $\bm{k}_1, \bm{k}_2, \ldots, \bm{k}_s$
        の順に式 \eqref{eq:ode_runge-kutta_k-law} を $\bm{k}_i$ について解くことで計算できる．
        このような場合は
        \index{はんいんてきRunge-Kuttaほう@半陰的 Runge-Kutta 法}
        半陰的 Runge-Kutta 法と呼ばれる．
        \footnote{Diagonally implicit Runge-Kutta (DIRK) とも呼ばれる \cite{Hairer1991}．}
    \item[陰的 Runge-Kutta 法 (Implicit Runge-Kutta method, IRK method)]
        $j > i$ でも $a_{ij} \neq 0$ となる係数が存在する場合，
        $\bm{k}i$ は $i = 1, 2, \ldots, s$ について連立した
        式 \eqref{eq:ode_runge-kutta_k-law} を $\bm{k}_i$ について解くことで計算する．
        このような場合は
        \index{いんてきRunge-Kuttaほう@陰的 Runge-Kutta 法}
        陰的 Runge-Kutta 法と呼ばれる．
        \footnote{半陰的 Runge-Kutta 法まで含めて陰的 Runge-Kutta 法と呼ばれていることもある．}
\end{description}

陽的 Runge-Kutta 法の方が計算は単純だが，
陰的 Runge-Kutta 法は

\begin{itemize}
    \item \index{かたいけい@硬い系} 硬い系と呼ばれる比較的不安定な微分方程式で解が安定しやすい．
    \item 陽的 Runge-Kutta 法よりも少ない段数でより高い次数を出せる．
          （後述する公式の実例を見ると分かる．）
\end{itemize}

といった利点を持つ．
そのため，解が安定するようにステップ幅を調整した場合，
陰的 Runge-Kutta 法の方がステップ幅を大きくとることができ，
目的の時刻 $t$ までの解を得るために必要な計算時間は少なくなる場合がある．

\index{じすう@次数}
また，Runge-Kutta 法の公式の精度を示す数値として次数が存在する．
変数の近似値 $\bm{y}(t + h)$ が厳密解の Tailor 展開が $p$ じまで一致する場合，
その公式は $p$ 次といい，$p$ は次数と呼ばれる．
変数の近似値 $\bm{y}(t + h)$ の精度は $h^{p+1}$ オーダーとなる．

\section{埋め込み型公式}

\index{うめこみがたのこうしき@埋め込み型の公式}
Runge-Kutta 法の公式の中には，複数の $c_i$ の組を持つものがある
（表 \ref{table:ode_runge-kutta_butcher-array-rkf45} の例を参照）．
そのような公式では，次のような 2 つの近似値を得ることができる．
\begin{align}
    \bm{y}(t + h)   & = \bm{y}(t) + \sum_{i=1}^s c_i \bm{k}_i     \\
    \bm{y}^*(t + h) & = \bm{y}^*(t) + \sum_{i=1}^s c_i^* \bm{k}_i
\end{align}
これらの差により誤差の近似値を求めることができる．
\begin{align}
    \bm{y}(t + h) - \bm{y}^*(t + h) & = \sum_{i=1}^s (c_i - c_i^*) \bm{k}_i
\end{align}
2 つの異なる公式を用いることによっても同じことはできるが，
埋め込み型の公式の方が $\bm{k}_i$ を共有できて効率が良い．

\subsection{ステップ幅の自動更新}

埋め込み型公式を用いると，次のように現在のステップ幅から次のステップ幅 $\hat{h}$ の適正値を推定できる
\cite[4.1 節 (a)]{Mitsui1993}．
まず，$c_i$ と $c_i^*$ のうち次数が低い方の次数を $p$ とすると，
\begin{align}
    \left| \bm{y}(t + h) - \bm{y}^*(t + h) \right| \approx |Ah^{p+1}|
    \label{eq:ode_runge-kutta_error-using-embedded-formula}
\end{align}
のように書ける．
そこで，誤差の許容量を $\epsilon_{tol}$ としたとき，次の方程式が成り立つようにする．
\begin{equation}
    \frac{\hat{h}^{p+1}}{h^{p+1}}
    = \frac{\epsilon_{tol}}{\left| \bm{y}(t + h) - \bm{y}^*(t + h) \right|}
\end{equation}
これを $\hat{h}$ について解くと，次のようになる．
\begin{equation}
    \hat{h} = h
    \left(\frac{\epsilon_{tol}}{\left| \bm{y}(t + h) - \bm{y}^*(t + h) \right|}\right)^{\frac{1}{p+1}}
    \label{eq:ode_runge-kutta_auto-next-step-size}
\end{equation}

以上を元に，
Algorithm \ref{alg:ode_runge-kutta_auto-step-size-with-embedded-formula}
のように自動でステップサイズを決定することができる．
Algorithm \ref{alg:ode_runge-kutta_auto-step-size-with-embedded-formula}
における係数 $f_{safe}$ は安全係数で
$f_{safe} = 0.8, 0.9, (0.25)^{1/(p+1)}, (0.38)^{1/(p+1)}$
といった値が用いられ，
ステップ幅の倍率の最大値 $f_{max}$ は
1.5 から 5 までの値が用いられる
\cite[Section II.4]{Hairer1993}．
なお，解のベクトルの各次元について誤差の許容量を指定する場合，解の次元を $d$ として
\begin{equation}
    err = \sqrt{\frac{1}{d} \sum_{i=1}^d \left(\frac{[\bm{y}(t + h) - \bm{y}^*(t + h)]_i}{[\epsilon_{tol}]_i} \right)^2}
    \label{eq:ode_runge-kutta_auto-next-step-size-multi-dimension-error}
\end{equation}
のように平均をとり，式 \eqref{eq:ode_runge-kutta_auto-next-step-size} の代わりに
\begin{equation}
    \hat{h} = h
    \left(\frac{1}{err}\right)^{\frac{1}{p+1}}
    \label{eq:ode_runge-kutta_auto-next-step-size-multi-dimension}
\end{equation}
を用いる方法も考えられている
\cite[Section II.4]{Hairer1993}．

\begin{algorithm}[tbp]
    \caption{式 \eqref{eq:ode_runge-kutta_auto-next-step-size} を利用したステップサイズの自動決定 %
        \cite[4.1 節 (a)]{Mitsui1993}, \cite[Section II.4]{Hairer1993}}
    \label{alg:ode_runge-kutta_auto-step-size-with-embedded-formula}
    \begin{algorithmic}
        \Procedure{StepWithAutoStepSize}{$\bm{f}, t, \bm{y}(t), h$}
        \Loop
        \State 現在のステップ幅 $h$ で 1 ステップ計算し，推定値 $\bm{y}(t + h)$, $\bm{y}^*(t+h)$ を計算する
        \If{$|\bm{y}(t + h) - \bm{y}^*(t + h)| < \epsilon_{tol}$}
        \State $f_{h} \gets \left(\epsilon_{tol} / \left| \bm{y}(t + h) - \bm{y}^*(t + h) \right|\right)^{\frac{1}{p+1}}$
        \Comment 式 \eqref{eq:ode_runge-kutta_auto-next-step-size} における倍率
        \State $f_h \gets f_{safe} f_h$
        \Comment $f_{safe}$ は安全係数 \cite[4.1 節 (a)]{Mitsui1993}, \cite[Section II.4]{Hairer1993}
        \If{$f_h > f_{max}$}
        \Comment 小さい推定誤差によりステップ幅が大きくなりすぎることを防ぐ \cite[Section II.4]{Hairer1993}
        \State $f_h \gets f_{max}$
        \EndIf
        \If{$f_h < f_{min}$}
        \Comment 倍率に下限を持たせることも有用 \cite[Section II.4]{Hairer1993}
        \State $f_h \gets f_{min}$
        \EndIf
        \State $h \gets f_h h$
        \State \Return $h$, $\bm{y}(t + h)$
        \EndIf
        \State $h \gets r h$ \Comment 比率 $r \in (0, 1)$ でステップサイズを縮小する
        \EndLoop
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

\subsection{PI 制御によるステップ幅の自動更新}

\index{PI せいぎょ@PI 制御}
ステップ幅を更新する方法として，前節の式
\eqref{eq:ode_runge-kutta_auto-next-step-size-multi-dimension}
を制御に用いられる PI 制御により改良した手法が考案されている
\cite[Section IV.2]{Hairer1991}．

$n$ 回目の反復におけるステップ幅を $h_n$，
式 \eqref{eq:ode_runge-kutta_auto-next-step-size-multi-dimension-error}
の相対的な推定誤差の比率を $err_n$ とする．
そこで，入力 $C = \log{h_n}$ を適切に変更することにより
出力 $\theta = \log{err_n}$ を制御することを考える
\footnote{前節と表記の整合を取るため，%
    元の文献 \cite[Section IV.2]{Hairer1991} とは少し異なる式になっている．}．
このとき，PI 制御の式
\footnote{右辺第一項は積分項 （Integral feedback），%
    右辺第二項は比例項（Proportional feedback）であり，%
    2 つの頭文字から PI 制御と呼ばれる．}
\begin{equation}
    -\dot{C} = n_1 \theta + n_2 \dot{\theta}
\end{equation}
に対して次のような近似が考えられる．
\begin{equation}
    -(\log{h_{n+1}} - \log{h_n}) = n_1 \log{err_n} + n_2 (\log{err_{n}} - \log{err_{n-1}})
\end{equation}

$\alpha = n_1 + n_2$, $\beta = n_2$ として式を整理すると次のようになる．
\begin{equation}
    h_{n+1} = h_n \frac{(err_{n-1})^\beta}{(err_n)^\alpha}
    \label{eq:ode_runge-kutta_auto-next-step-size-pi}
\end{equation}
これを用いて
Algorithm \ref{alg:ode_runge-kutta_auto-step-size-with-embedded-formula}
のようにステップ幅の自動更新を行う．
パラメータ $\alpha$, $\beta$ には次のような値が用いられる．
\begin{itemize}
    \item $\alpha = 1 / (p + 1)$, $\beta = 0.08$. \cite[Section IV.2]{Hairer1991}
    \item $\alpha = 0.7 / (p + 1)$, $\beta = 0.4 / (p + 1)$. \cite{Gustafsson1991}
\end{itemize}

\subsection{ステップ幅の簡易的な自動更新}

推定誤差をもとにしたステップ幅の更新方法としては，
単純化した
Algorithm \ref{alg:ode_runge-kutta_auto-step-size-simple}
のような手法も存在する．

\begin{algorithm}[tbp]
    \caption{簡易的なステップサイズの自動決定 \cite[4.1 節 (a)]{Mitsui1993}}
    \label{alg:ode_runge-kutta_auto-step-size-simple}
    \begin{algorithmic}
        \Procedure{StepWithAutoStepSize}{$\bm{f}, t, \bm{y}(t), h$}
        \Loop
        \State 現在のステップ幅 $h$ で 1 ステップ計算し，推定値 $\bm{y}(t + h)$, $\bm{y}^*(t+h)$ を計算する
        \If{$|\bm{y}(t + h) - \bm{y}^*(t + h)| < \epsilon_{tol}$}
        \If{$|\bm{y}(t + h) - \bm{y}^*(t + h)| < \frac{1}{2^{p+1}} \epsilon_{tol}$}
        \Comment ステップサイズを 2 倍にしても許容誤差の範囲内になる
        \State $h \gets 2 h$
        \EndIf
        \State \Return $h$, $\bm{y}(t + h)$
        \EndIf
        \State $h \gets r h$ \Comment 比率 $r \in (0, 1)$ でステップサイズを縮小する
        \EndLoop
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

\subsection{初回のステップ幅の自動決定}

ここまでに示した方法では
何らかのステップ幅が与えられている状態を前提としているが，
初期値問題における最初のステップでは人間が適当なステップ幅を与えない限り
ステップ幅が存在しない状態から始めることになる．
そこで，初回のステップ幅を自動決定する方法について
文献 \cite[Section II.4]{Hairer1993} で示されている方法を
Algorithm \ref{alg:ode_runge-kutta_auto-step-size-init}
に示しておく．

\begin{algorithm}[tbp]
    \caption{初期ステップサイズの自動決定 \cite[Section II.4]{Hairer1993}}
    \label{alg:ode_runge-kutta_auto-step-size-init}
    \begin{algorithmic}
        \Procedure{DetermineInitialStepSize}{$\bm{f}, \bm{y}(0)$}
        \State $d_0 \gets \|\bm{y}_0\|_{tol}$
        \Comment ノルム $\| \cdot \|_{tol}$ は
        式 \eqref{eq:ode_runge-kutta_auto-next-step-size-multi-dimension-error} によるもの
        \State $d_1 \gets \|\bm{f}(0, \bm{y}_0)\|_{tol}$
        \If{$d_0 \ge 10^{-5}$ and $d_1 \ge 10^{-5}$}
        \State $h_0 \gets 0.01 d_0 / d_1$
        \Comment 陽的 Euler 法（\ref{sec:ode_runge-kutta_explicit-euler} 節）における変化量を小さくする
        \Else
        \State $h_0 \gets 10^{-6}$
        \EndIf
        %
        \State $\bm{y}_1 \gets \bm{y}_0 + h_0 \bm{f}(0, \bm{y}_0)$
        \Comment 陽的 Euler 法の 1 ステップ分の計算を行う
        %
        \State $d_2 \gets \|\bm{f}(h_0, \bm{y}_1) - \bm{f}(0, \bm{y}_0)\|_{tol} / h_0$
        \Comment 2 階導関数の評価値
        %
        \If{$\max{\{d_1, d_2\}} > 10^{-15}$}
        \State $h_1 \gets \sqrt[p+1]{0.01 / \max{\{d_1, d_2\}}}$
        \Else
        \State $h_1 \gets \max{\{10^{-6}, 10^{-3} h_0\}}$
        \EndIf
        %
        \State $h \gets \min{\{100 h_0, h_1\}}$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

\section{埋め込み型でない公式による誤差の評価}

埋め込み型でない公式でも
式 \eqref{eq:ode_runge-kutta_error-using-embedded-formula} のように
誤差の評価を行い
Algorithm \ref{alg:ode_runge-kutta_auto-step-size-with-embedded-formula}
のようにステップサイズを自動決定を行う方法が考えられており，
Milne's device \cite[4.1 節 (b)]{Mitsui1993} と呼ばれる．
\index{Milne's device}

次のように Runge-Kutta 法を適用する演算子を考える．
\begin{equation}
    F[\bm{f}, t, \bm{y}(t), h] \equiv \bm{y}(t) + \sum_{i=1}^s c_i \bm{k}_i
\end{equation}
使用した公式の次数が $p$ であれば，厳密解 $\overline{\bm{y}(t + h)}$ との誤差は
\begin{equation}
    F[\bm{f}, t, \bm{y}(t), h] - \overline{\bm{y}(t + h)} = A h^{p+1} + O(h^{p+2})
\end{equation}
のようになる．ステップサイズを半分にして 2 ステップ解くと
\begin{align}
    F\left[\bm{f}, t, \bm{y}(t), \frac{1}{2}h\right] - \overline{\bm{y}\left(t + \frac{1}{2}h\right)}
     & = \frac{1}{2^{p+1}} A h^{p+1} + O(h^{p+2})
    \\
    F\left[\bm{f}, t + \frac{h}{2}, F\left[\bm{f}, t, \bm{y}(t), \frac{1}{2}h\right], \frac{1}{2}h\right]
    - \overline{\bm{y}(t + h)}
     & = \frac{1}{2^{p+1}} (A + A') h^{p+1} + O(h^{p+2})
\end{align}
のようになる．よって，
\begin{equation}
    F[\bm{f}, t, \bm{y}(t), h]
    - F\left[\bm{f}, t + \frac{h}{2}, F\left[\bm{f}, t, \bm{y}(t), \frac{1}{2}h\right], \frac{1}{2}h\right]
    = \left(A + \frac{1}{2^{p+1}} (A + A')\right) h^{p+1}
\end{equation}
となる．
これを用いると，埋め込み型の公式と同様に
Algorithm \ref{alg:ode_runge-kutta_auto-step-size-with-embedded-formula}
を用いることができる．

\section{陰的 Runge-Kutta 法における方程式の解法}

陰的 Runge-Kutta 法においては，
式 \eqref{eq:ode_runge-kutta_k-law} を方程式として解く必要がある．
数値解法に頼りたくなるような状況下において関数 $\bm{f}$ は非線形であるため
\footnote{関数 $\bm{f}$ が線形な場合，行列の指数関数による一般解が存在し，%
    固有値分解により簡単に解を得ることが可能であるため，%
    あえて Runge-Kutta 法を使用する必要はない．}，
Newton-Raphson 法（\ref{chap:root-finding_newton-raphson} 章）のような
非線形方程式の数値解法を用いる必要がある．

\subsection{半陰的公式の場合}\label{sec:ode_runge-kutta_semi-implicit-equation-solving}

半陰的公式の場合，$i = 1, 2, \ldots, s$ のそれぞれについて以下の方程式を解く必要がある．
\begin{equation}
    \bm{F}_i(\bm{k}_i)
    \equiv \bm{k}_i - \bm{f}\left(t + b_i h, \bm{y}(t) + h \sum_{j = 1}^i a_{ij} \bm{k}_j \right)
    = \bm{0}
    \label{eq:ode_runge-kutta_semi-implicit-equation}
\end{equation}

この方程式の数値解法として
Newton-Raphson 法を用いる場合，Jacobian
\begin{equation}
    \left. \frac{\partial \bm{F}_i}{\partial \bm{k}_i} \right|_{\bm{k}_i = \bm{k}_i}
    = I - h a_{ii}
    \left. \frac{\partial \bm{f}}{\partial \bm{y}}
    \right|_{t = t + b_i h, \bm{y} = \bm{y}(t) + h \sum_{j = 1}^i a_{ij} \bm{k}_j}
\end{equation}
を使用する必要がある．
Newton-Raphson 法における更新式は次のようになる．
\begin{equation}
    (\bm{k}_i)_{n+1} = (\bm{k}_i)_{n}
    - \left(\left. \frac{\partial \bm{F}_i}{\partial \bm{k}_i} \right|_{\bm{k}_i = \bm{k}_i}\right)^{-1}
    \bm{F}_i(\bm{k}_i)
\end{equation}
Newton-Raphson 法の各反復ごとに更新された Jacobian の LU 分解を求める必要がある．

ステップ幅を十分小さくとっている場合，
Jacobian の $\bm{k}_i$ に応じた変化量は少ないため，
Jacobian を $\bm{k}_i = \bm{0}$ のときの
\begin{equation}
    J \equiv I - h a_{ii}
    \left. \frac{\partial \bm{f}}{\partial \bm{y}}
    \right|_{t = t + b_i h, \bm{y} = \bm{y}(t)}
\end{equation}
に固定するという近似もあり得る
\cite[6.2 節 (c)]{Mitsui1993}．
この場合，1 段に 1 回だけ Jacobian とその LU 分解を計算すれば良い
\footnote{$d$ 次元の LU 分解において，係数行列が更新された場合は $d^3$ オーダーの時間がかかり，%
    係数行列が変わらず適応先のベクトルのみが更新された場合は $d^2$ オーダーの時間で済む．%
    対象とする常微分方程式の自由度の数が多いほど効果が大きくなる．}．

\subsection{陰的公式の場合}

半陰的公式でなく陰的公式の場合，
必要な方程式は次元が増えた次のようなものになる．
\begin{equation}
    \bm{F}_i(\bm{k}_i)
    \equiv
    \begin{pmatrix}
        \bm{k}_1 - \bm{f}\left(t + b_1 h, \bm{y}(t) + h \sum_{j = 1}^s a_{1j} \bm{k}_j \right) \\
        \bm{k}_2 - \bm{f}\left(t + b_2 h, \bm{y}(t) + h \sum_{j = 1}^s a_{2j} \bm{k}_j \right) \\
        \vdots                                                                                 \\
        \bm{k}_s - \bm{f}\left(t + b_s h, \bm{y}(t) + h \sum_{j = 1}^s a_{sj} \bm{k}_j \right) \\
    \end{pmatrix}
    = \bm{0}
    \label{eq:ode_runge-kutta_implicit-equation}
\end{equation}

Jacobian は次のようになる．
\begin{align}
    \left. \frac{\partial \bm{F}_i}{\partial (\bm{k}_1, \bm{k}_2, \ldots, \bm{k}_s)}
    \right|_{\bm{k}_i = \bm{k}_i}
    = I -
    \begin{pmatrix}
        J_{11} & J_{12} & \cdots & J_{1s} \\
        J_{21} & J_{22} & \cdots & J_{2s} \\
        \vdots & \vdots & \ddots & \vdots \\
        J_{s1} & J_{s2} & \cdots & J_{ss}
    \end{pmatrix}
    \\
    J_{ij} = h a_{ij} \left. \frac{\partial \bm{f}}{\partial \bm{y}}
    \right|_{t = t + c_i h, \bm{y} = \bm{y}(t) + h \sum_{l = 1}^i a_{il} \bm{k}_l}
\end{align}

半陰的公式と同様に，
上記の Jacobian を $\bm{k}_i = \bm{0}$ のときのものに固定することで
計算時間を減らすことが考えられる．
陰的公式では Jacobian のサイズが大きくなるため，
Jacobian を固定することの効果はより大きくなる
\footnote{$d$ 次元の常微分方程式に対して $s$ 段公式を使用すると，%
    Jacobian は $ds$ 次元の正方行列となる．}．

\subsection{陰的公式の別の定式化}\label{sec:ode_runge-kutta_another-implicit-stage-solving}

ここまで示した解法は $i = 1, 2, \ldots, s$ の各段における方程式を
\begin{equation}
    \bm{k}_i = \bm{f}\left(t + b_i h, \bm{y}(t) + h \sum_{j = 1}^s a_{ij} \bm{k}_j \right)
\end{equation}
としているが，代わりに
\begin{equation}
    \bm{z}_i = h \sum_{j = 1}^s a_{ij} \bm{k}_j
\end{equation}
のような変数を導入し，方程式
\begin{equation}
    \bm{z}_i = h \sum_{j = 1}^s a_{ij} \bm{f}\left(t + b_j h, \bm{y}(t) + \bm{z}_j \right)
    \label{eq:ode_runge-kutta_implicit-equation-for-differences}
\end{equation}
を解くこともできる \cite[Section IV.8.]{Hairer1991}．

この形式の方程式は，$a_{sj} = c_j$ ($j = 1, \ldots, s$) が成り立つ場合に
次のステップの解の計算を
\begin{equation}
    \bm{y}(t + h) = \bm{y}(t) + \sum_{i=1}^s c_i \bm{k}_i
    = \bm{y}(t) + \bm{z}_s
\end{equation}
のように簡易化できるという利点を持っている．
なお，このように $a_{sj} = c_j$ ($j = 1, \ldots, s$) となる公式は
stiffly accurate \index{stiffly accurate} であると言われる
\cite[Section IV.6.]{Hairer1991}
\footnote{stiffly accurate な公式は，ただ計算が楽になるというだけでなく，%
    追加の条件を満たしていれば L 安定と呼ばれる安定性を満たす\cite[Section IV.3.]{Hairer1991}．}
．

\subsection{Jacobian の計算が困難な場合}

問題の次元の数が大きく Jacobian のメモリ容量が大きすぎる場合や，
Jacobian の計算式を用意するのが困難な場合など，
Jacobian を用いて Newton 法を実装するのが困難な場合がある．
そのような場合でも Newton 法で式
\eqref{eq:ode_runge-kutta_semi-implicit-equation},
\eqref{eq:ode_runge-kutta_implicit-equation},
\eqref{eq:ode_runge-kutta_implicit-equation-for-differences}
のような方程式を解くために
後述の GMRES (Generalized Minimal Residual) \index{GMRES} 法を組み合わせた
Newton-GMRES 法が用いられている
\cite{Blom2016, Blom2013}．

GMRES 法は Algorithm \ref{alg:ode_runge-kutta_gmres} のようにして解を計算する．
$H_m \in \setR^{(m + 1) \times m}$ に QR 分解を適用できる程度に小さい $m$ を用いることで，
解きたい方程式の次元が大きい場合でも方程式の近似解を計算することができる．
さらに，GMRES 法を複数回適用することで
解の精度を高めていくことができる
\cite{Golub2013,Blom2013}．
ここで問題となるのは $\bm{r}_k = A \bm{q}_k$ の計算だが，
Newton 法においては $A$ が Jacobian になるため，
\begin{equation}
    A \bm{q}_k
    =
    \frac{\partial \bm{F}}{\partial \bm{y}}
    \bm{q}_k
    \approx
    \frac{\bm{F}(\bm{y} + \epsilon \bm{q}_k) - \bm{F}(\bm{y})}{\epsilon}
\end{equation}
または，
\begin{equation}
    A \bm{q}_k
    =
    \frac{\partial \bm{F}}{\partial \bm{y}}
    \bm{q}_k
    \approx
    \frac{\bm{F}(\bm{y} + \epsilon \bm{q}_k) - \bm{F}(\bm{y} - \epsilon \bm{q}_k)}{2 \epsilon}
\end{equation}
のような近似を用いて実際の Jacobian の計算を回避する
\cite{Blom2016, Blom2013}．
なお，$\epsilon$ はマシンイプシロン $\epsilon_{machine}$ に対して
\begin{equation}
    \epsilon = \frac{\sqrt{\epsilon_{machine}}}{\|\bm{q}_k\|_2}
\end{equation}
のように選択する
\cite{Blom2016, Blom2013}．

\begin{algorithm}[tp]
    \caption{GMRES (Generalized Minimal Residual) \cite{Golub2013,Blom2013}}
    \label{alg:ode_runge-kutta_gmres}
    \begin{algorithmic}
        \Procedure{GMRES}{$A \in \setR^{n \times n}, \bm{b} \in \setR^n, \bm{x}_0 \in \setR^n, m \in \{1, 2, \ldots, n\}$}
        \State $k \gets 0$
        \State $\bm{r}_0 \gets \bm{b} - A \bm{x}_0$
        \State $\beta_0 \gets \|\bm{r}_0\|_2$
        \While{$\beta_k > 0$ and $k < m$}
        \State $\bm{q}_{k+1} \gets \frac{\bm{r}_k}{\beta_k}$
        \State $k \gets k + 1$
        \State $\bm{r}_k \gets A \bm{q}_k$
        \For{$i = 1, k$}
        \State $h_{ik} \gets \bm{q}_i^\top \bm{r}_k$
        \State $\bm{r}_k \gets \bm{r}_k - h_{ik} \bm{q}_i$
        \EndFor
        \State $\beta_k \gets \|\bm{r}_k\|_2$
        \State $h_{k+1,k} \gets \beta_k$
        \EndWhile
        \State Compute $\bm{y}_k = \min_{\bm{y} \in \setR^m} \|\beta_0 \bm{e}_1 - H_k \bm{y}\|_2$
        for $H_k = \{h_{ij}\}_{1 \le k + 1, 1 \le j \le k}$.
        \Comment $\bm{e}_1 = (1, 0, 0, \ldots, 0)$
        \State $\bm{x} \gets \bm{x}_0 + Q_k \bm{y}_k$
        \Comment $Q_k = (\bm{q}_1, \bm{q}_2, \ldots, \bm{q}_k) \in \setR^{n \times k}$
        \State \Return $\bm{x}$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}
